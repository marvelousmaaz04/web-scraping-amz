{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e389852c-dc50-4cae-bead-5f05ad0b38f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Fetching product links from page 1...\n",
      "ğŸ” Found 24 product links.\n",
      "â¡ï¸ Navigating to the next page.\n",
      "ğŸ” Fetching product links from page 2...\n",
      "ğŸ” Found 24 product links.\n",
      "â¡ï¸ Navigating to the next page.\n",
      "ğŸ” Fetching product links from page 3...\n",
      "ğŸ” Found 24 product links.\n",
      "âœ… Found 72 products across 3 pages.\n",
      "ğŸ“¦ Scraping Product: (1/72)\n",
      "ğŸ“¦ Scraping Product: (2/72)\n",
      "ğŸ“¦ Scraping Product: (3/72)\n",
      "ğŸ“¦ Scraping Product: (4/72)\n",
      "ğŸ“¦ Scraping Product: (5/72)\n",
      "ğŸ“¦ Scraping Product: (6/72)\n",
      "ğŸ“¦ Scraping Product: (7/72)\n",
      "ğŸ“¦ Scraping Product: (8/72)\n",
      "ğŸ“¦ Scraping Product: (9/72)\n",
      "ğŸ“¦ Scraping Product: (10/72)\n",
      "ğŸ“¦ Scraping Product: (11/72)\n",
      "ğŸ“¦ Scraping Product: (12/72)\n",
      "ğŸ“¦ Scraping Product: (13/72)\n",
      "ğŸ“¦ Scraping Product: (14/72)\n",
      "ğŸ“¦ Scraping Product: (15/72)\n",
      "ğŸ“¦ Scraping Product: (16/72)\n",
      "ğŸ“¦ Scraping Product: (17/72)\n",
      "ğŸ“¦ Scraping Product: (18/72)\n",
      "ğŸ“¦ Scraping Product: (19/72)\n",
      "ğŸ“¦ Scraping Product: (20/72)\n",
      "ğŸ“¦ Scraping Product: (21/72)\n",
      "ğŸ“¦ Scraping Product: (22/72)\n",
      "ğŸ“¦ Scraping Product: (23/72)\n",
      "ğŸ“¦ Scraping Product: (24/72)\n",
      "ğŸ“¦ Scraping Product: (25/72)\n",
      "ğŸ“¦ Scraping Product: (26/72)\n",
      "ğŸ“¦ Scraping Product: (27/72)\n",
      "ğŸ“¦ Scraping Product: (28/72)\n",
      "ğŸ“¦ Scraping Product: (29/72)\n",
      "ğŸ“¦ Scraping Product: (30/72)\n",
      "ğŸ“¦ Scraping Product: (31/72)\n",
      "ğŸ“¦ Scraping Product: (32/72)\n",
      "ğŸ“¦ Scraping Product: (33/72)\n",
      "ğŸ“¦ Scraping Product: (34/72)\n",
      "ğŸ“¦ Scraping Product: (35/72)\n",
      "ğŸ“¦ Scraping Product: (36/72)\n",
      "ğŸ“¦ Scraping Product: (37/72)\n",
      "ğŸ“¦ Scraping Product: (38/72)\n",
      "ğŸ“¦ Scraping Product: (39/72)\n",
      "ğŸ“¦ Scraping Product: (40/72)\n",
      "ğŸ“¦ Scraping Product: (41/72)\n",
      "ğŸ“¦ Scraping Product: (42/72)\n",
      "ğŸ“¦ Scraping Product: (43/72)\n",
      "ğŸ“¦ Scraping Product: (44/72)\n",
      "ğŸ“¦ Scraping Product: (45/72)\n",
      "ğŸ“¦ Scraping Product: (46/72)\n",
      "ğŸ“¦ Scraping Product: (47/72)\n",
      "ğŸ“¦ Scraping Product: (48/72)\n",
      "ğŸ“¦ Scraping Product: (49/72)\n",
      "ğŸ“¦ Scraping Product: (50/72)\n",
      "ğŸ“¦ Scraping Product: (51/72)\n",
      "ğŸ“¦ Scraping Product: (52/72)\n",
      "ğŸ“¦ Scraping Product: (53/72)\n",
      "ğŸ“¦ Scraping Product: (54/72)\n",
      "ğŸ“¦ Scraping Product: (55/72)\n",
      "ğŸ“¦ Scraping Product: (56/72)\n",
      "ğŸ“¦ Scraping Product: (57/72)\n",
      "ğŸ“¦ Scraping Product: (58/72)\n",
      "ğŸ“¦ Scraping Product: (59/72)\n",
      "ğŸ“¦ Scraping Product: (60/72)\n",
      "ğŸ“¦ Scraping Product: (61/72)\n",
      "ğŸ“¦ Scraping Product: (62/72)\n",
      "ğŸ“¦ Scraping Product: (63/72)\n",
      "ğŸ“¦ Scraping Product: (64/72)\n",
      "ğŸ“¦ Scraping Product: (65/72)\n",
      "ğŸ“¦ Scraping Product: (66/72)\n",
      "ğŸ“¦ Scraping Product: (67/72)\n",
      "ğŸ“¦ Scraping Product: (68/72)\n",
      "ğŸ“¦ Scraping Product: (69/72)\n",
      "ğŸ“¦ Scraping Product: (70/72)\n",
      "ğŸ“¦ Scraping Product: (71/72)\n",
      "ğŸ“¦ Scraping Product: (72/72)\n",
      "âœ… Data saved to 'amazon_products_selenium_pagination.csv' successfully!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Setup Selenium WebDriver (with headless mode disabled for debugging)\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # To run in headless mode\n",
    "# options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--window-size=1920x1080\")\n",
    "# options.add_argument(\"--log-level=3\")  # Suppress warnings\n",
    "\n",
    "# Initialize WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Amazon Search Results URL\n",
    "URL = \"https://www.amazon.in/s?rh=n%3A6612025031&fs=true&ref=lp_6612025031_sar\"\n",
    "\n",
    "def get_product_links(url):\n",
    "    \"\"\"\n",
    "    Extracts all product links from the Amazon search results page.\n",
    "    Uses Selenium to navigate and find links dynamically.\n",
    "    \"\"\"\n",
    "    product_links = []\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(3)  # Allow time for page to load\n",
    "\n",
    "        # Scroll to the bottom to load more products\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Give some time for elements to load\n",
    "\n",
    "        # Find all product links\n",
    "        product_elements = driver.find_elements(By.CSS_SELECTOR, \"a.a-link-normal.s-no-outline\")\n",
    "        product_links = [element.get_attribute(\"href\") for element in product_elements if element.get_attribute(\"href\")]\n",
    "\n",
    "        print(f\"ğŸ” Found {len(product_links)} product links.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error fetching product links: {e}\")\n",
    "\n",
    "    return product_links\n",
    "\n",
    "def get_product_details(url):\n",
    "    \"\"\"\n",
    "    Extracts product details from an individual product page.\n",
    "    Handles missing elements to avoid errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)  # Allow time for page to load fully\n",
    "\n",
    "        # Extract product title\n",
    "        title_element = driver.find_elements(By.ID, \"productTitle\")\n",
    "        title = title_element[0].text.strip() if title_element else \"N/A\"\n",
    "\n",
    "        # Extract product price\n",
    "        price_element = driver.find_elements(By.CLASS_NAME, \"a-price-whole\")\n",
    "        price = price_element[0].text.strip() if price_element else \"N/A\"\n",
    "\n",
    "        # Extract product rating\n",
    "        # Locate the outermost span element by its ID\n",
    "        rating_outer_span = driver.find_element(By.ID, \"acrPopover\")\n",
    "        \n",
    "        # Get the value of the title attribute\n",
    "        rating = rating_outer_span.get_attribute(\"title\")\n",
    "        rating = rating.split(\" \")[0]\n",
    "      \n",
    "\n",
    "        # Extract seller information\n",
    "        seller_element = driver.find_elements(By.ID, \"sellerProfileTriggerId\")\n",
    "        seller = seller_element[0].text.strip() if seller_element else \"N/A\"\n",
    "\n",
    "        # Extract availability status\n",
    "        availability_element = driver.find_elements(By.ID, \"availability\")\n",
    "        availability = availability_element[0].text.strip() if availability_element else \"N/A\"\n",
    "\n",
    "        # Extract total number of ratings\n",
    "        total_ratings_element = driver.find_elements(By.ID, \"acrCustomerReviewText\")\n",
    "        total_ratings = total_ratings_element[0].text.strip().replace(\" ratings\", \"\") if total_ratings_element else \"N/A\"\n",
    "\n",
    "        return {\n",
    "            \"Title\": title,\n",
    "            \"Price\": price,\n",
    "            \"Rating (Out of 5)\": rating,\n",
    "            \"Seller\": seller,\n",
    "            \"Availability\": availability,\n",
    "            \"Total Ratings\": total_ratings,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error fetching product details for {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def go_to_next_page():\n",
    "    \"\"\"\n",
    "    Goes to the next page of the Amazon search results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find the 'Next' button and click it\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, \"a.s-pagination-next\")\n",
    "        next_button.click()\n",
    "        time.sleep(3)  # Allow time for the next page to load\n",
    "        print(\"â¡ï¸ Navigating to the next page.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error navigating to next page: {e}\")\n",
    "\n",
    "# Step 1: Get all product links (for 5 pages)\n",
    "product_links = []\n",
    "total_pages = 3\n",
    "for page in range(1,total_pages+1):\n",
    "    print(f\"ğŸ” Fetching product links from page {page}...\")\n",
    "    product_links.extend(get_product_links(URL))\n",
    "    \n",
    "    # Go to the next page if it's not the last one\n",
    "    if page < 3:  # Stop at the last page\n",
    "        go_to_next_page()\n",
    "\n",
    "print(f\"âœ… Found {len(product_links)} products across {total_pages} pages.\")\n",
    "\n",
    "# Step 2: Scrape product details\n",
    "product_data = []\n",
    "for index, link in enumerate(product_links):\n",
    "    print(f\"ğŸ“¦ Scraping Product: ({index + 1}/{len(product_links)})\")\n",
    "    details = get_product_details(link)\n",
    "    if details:\n",
    "        product_data.append(details)\n",
    "\n",
    "# Step 3: Store the data in a Pandas DataFrame and save as CSV\n",
    "if product_data:\n",
    "    df = pd.DataFrame(product_data)\n",
    "    df.to_csv(\"amazon_products_selenium_pagination.csv\", index=False)\n",
    "    print(\"âœ… Data saved to 'amazon_products_selenium_pagination.csv' successfully!\")\n",
    "else:\n",
    "    print(\"âš ï¸ No data scraped. Please check your script or Amazon's page structure.\")\n",
    "\n",
    "# Close the Selenium WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24106cbd-615d-4fff-a1fe-58cf05af688a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
