{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "863263e5-8997-4df8-ac15-51d9b3a9d873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Fetching product links...\n",
      "ğŸ” Found 24 product links.\n",
      "âœ… Found 24 products.\n",
      "ğŸ“¦ Scraping Product: (1/24)\n",
      "ğŸ“¦ Scraping Product: (2/24)\n",
      "ğŸ“¦ Scraping Product: (3/24)\n",
      "ğŸ“¦ Scraping Product: (4/24)\n",
      "ğŸ“¦ Scraping Product: (5/24)\n",
      "ğŸ“¦ Scraping Product: (6/24)\n",
      "ğŸ“¦ Scraping Product: (7/24)\n",
      "ğŸ“¦ Scraping Product: (8/24)\n",
      "ğŸ“¦ Scraping Product: (9/24)\n",
      "ğŸ“¦ Scraping Product: (10/24)\n",
      "ğŸ“¦ Scraping Product: (11/24)\n",
      "ğŸ“¦ Scraping Product: (12/24)\n",
      "ğŸ“¦ Scraping Product: (13/24)\n",
      "ğŸ“¦ Scraping Product: (14/24)\n",
      "ğŸ“¦ Scraping Product: (15/24)\n",
      "ğŸ“¦ Scraping Product: (16/24)\n",
      "ğŸ“¦ Scraping Product: (17/24)\n",
      "ğŸ“¦ Scraping Product: (18/24)\n",
      "ğŸ“¦ Scraping Product: (19/24)\n",
      "ğŸ“¦ Scraping Product: (20/24)\n",
      "ğŸ“¦ Scraping Product: (21/24)\n",
      "ğŸ“¦ Scraping Product: (22/24)\n",
      "ğŸ“¦ Scraping Product: (23/24)\n",
      "ğŸ“¦ Scraping Product: (24/24)\n",
      "âœ… Data saved to 'amazon_products_selenium.csv' successfully!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Setup Selenium WebDriver (with headless mode disabled for debugging)\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # To run in headless mode\n",
    "# options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--window-size=1920x1080\")\n",
    "# options.add_argument(\"--log-level=3\")  # Suppress warnings\n",
    "\n",
    "# Initialize WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Amazon Search Results URL\n",
    "URL = \"https://www.amazon.in/s?rh=n%3A6612025031&fs=true&ref=lp_6612025031_sar\"\n",
    "\n",
    "def get_product_links(url):\n",
    "    \"\"\"\n",
    "    Extracts all product links from the Amazon search results page.\n",
    "    Uses Selenium to navigate and find links dynamically.\n",
    "    \"\"\"\n",
    "    product_links = []\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(3)  # Allow time for page to load\n",
    "\n",
    "        # Scroll to the bottom to load more products\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Give some time for elements to load\n",
    "\n",
    "        # Find all product links\n",
    "        product_elements = driver.find_elements(By.CSS_SELECTOR, \"a.a-link-normal.s-no-outline\")\n",
    "        product_links = [element.get_attribute(\"href\") for element in product_elements if element.get_attribute(\"href\")]\n",
    "\n",
    "        print(f\"ğŸ” Found {len(product_links)} product links.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error fetching product links: {e}\")\n",
    "\n",
    "    return product_links\n",
    "\n",
    "def get_product_details(url):\n",
    "    \"\"\"\n",
    "    Extracts product details from an individual product page.\n",
    "    Handles missing elements to avoid errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)  # Allow time for page to load fully\n",
    "\n",
    "        # Extract product title\n",
    "        title_element = driver.find_elements(By.ID, \"productTitle\")\n",
    "        title = title_element[0].text.strip() if title_element else \"N/A\"\n",
    "\n",
    "        # Extract product price\n",
    "        price_element = driver.find_elements(By.CLASS_NAME, \"a-price-whole\")\n",
    "        price = price_element[0].text.strip() if price_element else \"N/A\"\n",
    "\n",
    "        # Extract product rating\n",
    "        # Locate the outermost span element by its ID\n",
    "        rating_outer_span = driver.find_element(By.ID, \"acrPopover\")\n",
    "        \n",
    "        # Get the value of the title attribute\n",
    "        rating = rating_outer_span.get_attribute(\"title\")\n",
    "        rating = rating.split(\" \")[0]\n",
    "     \n",
    "        # Extract seller information\n",
    "        seller_element = driver.find_elements(By.ID, \"sellerProfileTriggerId\")\n",
    "        seller = seller_element[0].text.strip() if seller_element else \"N/A\"\n",
    "\n",
    "        # Extract availability status\n",
    "        availability_element = driver.find_elements(By.ID, \"availability\")\n",
    "        availability = availability_element[0].text.strip() if availability_element else \"N/A\"\n",
    "\n",
    "        # Extract total number of ratings\n",
    "        total_ratings_element = driver.find_elements(By.ID, \"acrCustomerReviewText\")\n",
    "        total_ratings = total_ratings_element[0].text.strip().replace(\" ratings\", \"\") if total_ratings_element else \"N/A\"\n",
    "\n",
    "        return {\n",
    "            \"Title\": title,\n",
    "            \"Price\": price,\n",
    "            \"Rating (Out of 5)\": rating,\n",
    "            \"Seller\": seller,\n",
    "            \"Availability\": availability,\n",
    "            \"Total Ratings\": total_ratings,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error fetching product details for {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Step 1: Get all product links\n",
    "print(\"ğŸ” Fetching product links...\")\n",
    "product_links = get_product_links(URL)\n",
    "print(f\"âœ… Found {len(product_links)} products.\")\n",
    "\n",
    "# Step 2: Scrape product details\n",
    "product_data = []\n",
    "for index, link in enumerate(product_links):\n",
    "    print(f\"ğŸ“¦ Scraping Product: ({index + 1}/{len(product_links)})\")\n",
    "    details = get_product_details(link)\n",
    "    if details:\n",
    "        product_data.append(details)\n",
    "\n",
    "# Step 3: Store the data in a Pandas DataFrame and save as CSV\n",
    "if product_data:\n",
    "    df = pd.DataFrame(product_data)\n",
    "    df.to_csv(\"amazon_products_selenium.csv\", index=False)\n",
    "    print(\"âœ… Data saved to 'amazon_products_selenium.csv' successfully!\")\n",
    "else:\n",
    "    print(\"âš ï¸ No data scraped. Please check your script or Amazon's page structure.\")\n",
    "\n",
    "# Close the Selenium WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a5683-db52-47fb-af00-db9852de5394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
